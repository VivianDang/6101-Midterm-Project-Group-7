---
title: "Telco Customer Churn Project"
author: "Group7-Bug Tornado"
#date: "today"
date: "`r Sys.Date()`"
# this style requires installing rmdformats package 
output:
  html_document:
    code_folding: hide
    number_sections: false
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
---

```{r init, include=FALSE}
# some of common options (and the defaults) are: 
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right', 
library(ezids)
library(ggplot2)
library(ggpubr)
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "hide", message = F)
options(scientific=T, digits = 3) 
# options(scipen=9, digits = 3) 
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
```

# Telco Customer Churn
## Description
The Telco customer churn data contains information about a telephone company that provided home phone and Internet services to 7043 customers in California at the end of 2017 Quarter 3. It indicates which customers have left, stayed, or signed up for their service.  
Studying such data can help companies identify the characteristics of lost customers, identify potential, soon-to-be-lost customers and develop appropriate strategies to retain them.  
The dataset is WA_Fn-UseC_-Telco-Customer-Churn.csv.  

### variables

* `gender`: Female or Male
* `SeniorCitizen`: customer is a senior citizen or not (Yes, No)
* `Partner`: customer has a partner or not (Yes, No)
* `Dependents`: customer has dependents or not (Yes, No)
* `tenure`: number of months the customer has stayed with the company
* `PhoneService`: customer has a phone service or not (Yes, No)
* `MultipleLines`: customer has multiple lines or not (Yes, No, No phone service)
* `InternetService`: customer’s internet service provider (DSL, Fiber optic, No)
* `OnlineSecurity`: customer has online security or not (Yes, No, No internet service)
* `OnlineBackup`: customer has online backup or not (Yes, No, No internet service)
* `DeviceProtection`: customer has device protection or not (Yes, No, No internet service)
* `TechSupport`: customer has tech support or not (Yes, No, No internet service)
* `StreamingTV`: customer has streaming TV or not (Yes, No, No internet service)
* `StreamingMovies`: customer has streaming movies or not (Yes, No, No internet service)
* `Contract`: contract term of the customer (Month-to-month, One year, Two year)
* `PaperlessBilling`: customer has paperless billing or not (Yes, No)
* `PaymentMethod`: Electronic check, Mailed check, Bank transfer (automatic), Credit card (automatic)
* `MonthlyCharges`: amount charged monthly
* `TotalCharges`: total amount charged
* `Churn`: customer churned or not (Yes or No)

```{r import, include=FALSE}
customer <- data.frame(read.csv("WA_Fn-UseC_-Telco-Customer-Churn.csv"))
str(customer)
#head(customer)
```

```{r asfactor, include=FALSE}
for(i in 2:21){
  # tenure, MonthlyCharges, TotalCharges
  if (!(i %in% c(6, 19, 20))){
    customer[,i] = factor(customer[,i])
  }
}
levels(customer$SeniorCitizen) <- c("No", "Yes") # no=1, yes=2
str(customer)
```

```{r cleanNA, include=FALSE}
summary(customer)  # there are 11 NA in TotalCharges
customer <- na.omit(customer)
sum(is.na(customer))
```

## Logistic Regression

```{r 1.1Logistic Regression}
logistic_all = glm(Churn ~ gender + SeniorCitizen + Partner + Dependents + tenure
                         + PhoneService + MultipleLines + InternetService + OnlineSecurity
                         + OnlineBackup + DeviceProtection + TechSupport + StreamingTV
                         + StreamingMovies + Contract + PaperlessBilling + PaymentMethod
                         + MonthlyCharges + TotalCharges, data = customer, family = 'binomial')
summary(logistic_all)
xkabledply(logistic_all)

```
Delete `gender`

```{r 1.2Logistic Regression}
logistic_1 = glm(Churn ~ SeniorCitizen + Partner + Dependents + tenure
                         + PhoneService + MultipleLines + InternetService + OnlineSecurity
                         + OnlineBackup + DeviceProtection + TechSupport + StreamingTV
                         + StreamingMovies + Contract + PaperlessBilling + PaymentMethod
                         + MonthlyCharges + TotalCharges, data = customer, family = 'binomial')
summary(logistic_1)
xkabledply(logistic_1)

```
Delete `Partner`

```{r 1.3Logistic Regression}
logistic_2 = glm(Churn ~ SeniorCitizen + Dependents + tenure
                         + PhoneService + MultipleLines + InternetService + OnlineSecurity
                         + OnlineBackup + DeviceProtection + TechSupport + StreamingTV
                         + StreamingMovies + Contract + PaperlessBilling + PaymentMethod
                         + MonthlyCharges + TotalCharges, data = customer, family = 'binomial')
summary(logistic_2)
xkabledply(logistic_2)

```
Delete `PhoneService`

```{r 1.4Logistic Regression}
logistic_3 = glm(Churn ~ SeniorCitizen + Dependents + tenure
                         + MultipleLines + InternetService + OnlineSecurity
                         + OnlineBackup + DeviceProtection + TechSupport + StreamingTV
                         + StreamingMovies + Contract + PaperlessBilling + PaymentMethod
                         + MonthlyCharges + TotalCharges, data = customer, family = 'binomial')
summary(logistic_3)
xkabledply(logistic_3)

```
Delete `MultipleLines`

```{r 1.5Logistic Regression}
logistic_4 = glm(Churn ~ SeniorCitizen + Dependents + tenure
                         + InternetService + OnlineSecurity
                         + OnlineBackup + DeviceProtection + TechSupport + StreamingTV
                         + StreamingMovies + Contract + PaperlessBilling + PaymentMethod
                         + MonthlyCharges + TotalCharges, data = customer, family = 'binomial')
summary(logistic_4)
xkabledply(logistic_4)

```
Delete `OnlineBackup`


```{r 1.6Logistic Regression}
logistic_5 = glm(Churn ~ SeniorCitizen + Dependents + tenure
                         + InternetService + OnlineSecurity
                         + DeviceProtection + TechSupport + StreamingTV
                         + StreamingMovies + Contract + PaperlessBilling + PaymentMethod
                         + MonthlyCharges + TotalCharges, data = customer, family = 'binomial')
summary(logistic_5)
xkabledply(logistic_5)

```
Delete `DeviceProtection`

```{r 1.7Logistic Regression}
logistic_6 = glm(Churn ~ SeniorCitizen + Dependents + tenure
                         + InternetService + OnlineSecurity
                         + TechSupport + StreamingTV
                         + StreamingMovies + Contract + PaperlessBilling + PaymentMethod
                         + MonthlyCharges + TotalCharges, data = customer, family = 'binomial')
summary(logistic_6)
xkabledply(logistic_6)

```
Delete `PaymentMethod`

```{r 1.8Logistic Regression}
logistic_7 = glm(Churn ~ SeniorCitizen + Dependents + tenure
                         + InternetService + OnlineSecurity
                         + TechSupport + StreamingTV
                         + StreamingMovies + Contract + PaperlessBilling
                         + MonthlyCharges + TotalCharges, data = customer, family = 'binomial')
summary(logistic_7)
xkabledply(logistic_7)

```
Now all variables are significant.

```{r exp}
expcoeff1 = exp(coef(logistic_7))
summary(expcoeff1)
xkabledply( as.table(expcoeff1), title = "Exponential of coefficients in Churn" )

```

#### Confusion matrix 
```{r confusionMatrix, results='markup'}
loadPkg("regclass")
confusion_matrix(logistic_7)
xkabledply( confusion_matrix(logistic_7), title = "Confusion matrix from Logit Model" )
unloadPkg("regclass")
```

```{r confusion matrix, results=T}
loadPkg("regclass")
cfmatrix1 = confusion_matrix(logistic_7)
accuracy1 <- (cfmatrix1[1,1]+cfmatrix1[2,2])/cfmatrix1[3,3]
precision1 <- cfmatrix1[2,2]/(cfmatrix1[2,2]+cfmatrix1[1,2])
recall1 <- cfmatrix1[2,2]/(cfmatrix1[2,2]+cfmatrix1[2,1])
specificity1 <- cfmatrix1[1,1]/(cfmatrix1[1,1]+cfmatrix1[1,2])
F1_score1 <- 2*(precision1)*(recall1)/(precision1 + recall1)
accuracy1
precision1
recall1
specificity1
F1_score1
```
From confusion matrix, we can conclude that 
Accuracy =`r accuracy1`
Precision=`r precision1`
Recall=`r recall1`
Specificity=`r specificity1`
F1 score=`r F1_score1`

```{r roc_auc, results=T}
loadPkg("pROC") 
prob=predict(logistic_7, type = "response" )
customer$prob=prob
h = roc(Churn~prob, data=customer)
# auc(h) 
plot(h)
```
We have here the area-under-curve of `r auc(h)`, which is greater than 0.8. The model is considered a good fit.

```{r McFadden, results=T}
loadPkg("pscl")
ChurnLogitpr2 = pR2(logistic_7)
ChurnLogitpr2
unloadPkg("pscl") 
```
With the McFadden value of `r ChurnLogitpr2['McFadden']`, which is analogous to the coefficient of determination $R^2$, only about 27.8% of the variations in y is explained by the explanatory variables in the model.

## KNN

```{r Into Numeric}
customerNum = customer
# convert categorical variable as numeric 
for(i in 2:21){
  # tenure, MonthlyCharges, TotalCharges
  if (!(i %in% c(6, 19, 20))){
    customerNum[,i] = as.numeric(customerNum[,i])
  }
}
customerNum$customerID = NULL
str(customerNum)
```

```{r preproccessing}
customer_final=customerNum
customer_final$Churn <-  factor(customer_final$Churn)
str(customer_final)
cusKNN <- subset(customer_final, select=c(SeniorCitizen, Partner, Dependents, PaperlessBilling, OnlineSecurity, OnlineBackup, DeviceProtection, TechSupport, Contract, tenure, MonthlyCharges, Churn))
str(cusKNN)
cus_scale = cusKNN
cus_scale[10:11]<- scale(cusKNN[10:11], center = TRUE, scale = TRUE)
cus_scale$Churn <- customer_final$Churn
str(cus_scale)
```

```{r selectk}
loadPkg("class")
chooseK = function(k, train_set, val_set, train_class, val_class){
  
  # Build knn with k neighbors considered.
  set.seed(1)
  class_knn = knn(train = train_set,    #<- training set cases
                  test = val_set,       #<- test set cases
                  cl = train_class,     #<- category for classification
                  k = k) #,                #<- number of neighbors considered
                  # use.all = TRUE)       #<- control ties between class assignments. If true, all distances equal to the k-th largest are included
  
  tab = table(class_knn, val_class)
  #cm = confusionMatrix(class_knn, reference = cus_test_y ) # from caret library
  # print.confusionMatrix(cm)
  # 
  #cmaccu = cm$overall['Accuracy']
  
  # Calculate the accuracy.
  accu = sum(tab[row(tab) == col(tab)]) / sum(tab)                         
  cbind(k = k, accuracy = accu)
}
```

```{r KNNfull}
fullScale = customer_final
fullScale[c(5, 18, 19)]<- scale(fullScale[c(5, 18, 19)], center = TRUE, scale = TRUE)
str(fullScale)
set.seed(1)
customer_sampe <- sample(2, nrow(fullScale), replace=TRUE, prob=c(0.75, 0.25))
cus_train_full <- fullScale[customer_sampe==1, 1:19]
cus_test_full <- fullScale[customer_sampe==2, 1:19]
# y
cus_train_full_y <- fullScale[customer_sampe==1, 20]
cus_test_full_y <- fullScale[customer_sampe==2, 20]
```
Prepossessing the dataset: scale and centered the numerical variables, convert categorical variables as numeric.  

```{r results='markup'}
str(cus_train_full)
str(cus_test_full)
```

```{r selectionfull}
knn_full_different_k = sapply(seq(1, 21, by = 2),  #<- set k to be odd number from 1 to 21
                         function(x) chooseK(x, 
                                             train_set = cus_train_full,
                                             val_set = cus_test_full,
                                             train_class = cus_train_full_y,
                                             val_class = cus_test_full_y))

str(knn_full_different_k)
knn_full_different_k = data.frame(k = knn_full_different_k[1,],
                             accuracy = knn_full_different_k[2,])

library("ggplot2")

ggplot(knn_full_different_k,
       aes(x = k, y = accuracy)) +
  geom_line(color = "orange", size = 1.5) +
  geom_point(size = 3) + 
  labs(title = "accuracy vs k")
xkabledply((knn_full_different_k))
```
Select value `k=15`  

```{r KNNfull2}
pred_full <- knn(train = cus_train_full, test = cus_test_full, cl=cus_train_full_y, k=15)
pred_full
```

```{r confusion_matrix_full, results=T}
loadPkg("gmodels")
churnPredCross <- CrossTable(cus_test_full_y, pred_full, prop.chisq = FALSE)
```

### KNN with selected variables  

Prepossessing the dataset: scale and centered the numerical variables, convert categorical variables as numeric.
```{r results='markup'}
str(cus_scale)
```

```{r train_test_split}
set.seed(1)
customer_sampe <- sample(2, nrow(cus_scale), replace=TRUE, prob=c(0.75, 0.25))
cus_train <- cus_scale[customer_sampe==1, 1:11]
cus_test <- cus_scale[customer_sampe==2, 1:11]
# y
cus_train_y <- cus_scale[customer_sampe==1, 12]
cus_test_y <- cus_scale[customer_sampe==2, 12]
```

```{r, results='markup'}
str(cus_train)
str(cus_test)
```

```{r selection}
knn_different_k = sapply(seq(1, 21, by = 2),  #<- set k to be odd number from 1 to 21
                         function(x) chooseK(x, 
                                             train_set = cus_train,
                                             val_set = cus_test,
                                             train_class = cus_train_y,
                                             val_class = cus_test_y))

# Reformat the results to graph the results.
str(knn_different_k)
knn_different_k = data.frame(k = knn_different_k[1,],
                             accuracy = knn_different_k[2,])

# Plot accuracy vs. k.
# install.packages("ggplot2")
library("ggplot2")

ggplot(knn_different_k,
       aes(x = k, y = accuracy)) +
  geom_line(color = "orange", size = 1.5) +
  geom_point(size = 3) + 
  labs(title = "accuracy vs k")
xkabledply((knn_different_k))
```
Select value `k=11`  
```{r KNN}
pred <- knn(train = cus_train, test = cus_test, cl=cus_train_y, k=11)
knn.roc.prob <- attr(knn(train = cus_train, test = cus_test, cl=cus_train_y, k=11,prob = T),'prob')
pred
```

```{r confusion_matrix_KNN, results='markup'}
library("gmodels")
churnPredCross <- CrossTable(cus_test_y, pred, prop.chisq = FALSE)
```

```{r}
unloadPkg("class")
unloadPkg("gmodels")
```

## Classification Tree

```{r}
customerNum = customer
# convert categorical variable as numeric 
for(i in 2:20){
  # tenure, MonthlyCharges, TotalCharges
  if (!(i %in% c(6, 19, 20))){
    customerNum[,i] = as.numeric(customerNum[,i])
  }
}
customerNum <- subset(customerNum, select = -customerID)
```



```{r Classification Tree feature selection}
library(randomForest)
fit_im = randomForest(customerNum$Churn~., data=customerNum)
# Create an importance based on mean decreasing gini
# importance(fit_im)
varImpPlot(fit_im)
```

From the sorted importance picture, we can select the top 6 features to build the tree model.  


Then, firstly, try to find the best depths.

```{r Classification Tree depths result}
loadPkg("rpart")
loadPkg("caret")



# create an empty dataframe to store the results from confusion matrices
confusionMatrixResultDf = data.frame( Depth=numeric(0), Accuracy= numeric(0), Sensitivity=numeric(0), Specificity=numeric(0), Pos.Pred.Value=numeric(0), Neg.Pred.Value=numeric(0), Precision=numeric(0), Recall=numeric(0), F1=numeric(0), Prevalence=numeric(0), Detection.Rate=numeric(0), Detection.Prevalence=numeric(0), Balanced.Accuracy=numeric(0), row.names = NULL )

for (deep in 2:8) {
  kfit <- rpart(Churn ~ TotalCharges + MonthlyCharges + tenure + Contract +  OnlineSecurity + PaymentMethod, data=customerNum, method="class", control = list(maxdepth = deep) )
  # 
  cm = confusionMatrix( predict(kfit, type = "class"), reference = customerNum[, "Churn"] ) # from caret library
  # 
  cmaccu = cm$overall['Accuracy']
  # print( paste("Total Accuracy = ", cmaccu ) )
  # 
  cmt = data.frame(Depth=deep, Accuracy = cmaccu, row.names = NULL ) # initialize a row of the metrics 
  cmt = cbind( cmt, data.frame( t(cm$byClass) ) ) # the dataframe of the transpose, with k valued added in front
  confusionMatrixResultDf = rbind(confusionMatrixResultDf, cmt)
  # print("Other metrics : ")
}

unloadPkg("caret")
```


The summarized result is here:

```{r , results="asis"}
xkabledply(confusionMatrixResultDf, title="Churn Classification Trees summary with varying MaxDepth")
```

From depths 5, the accuracy is almost same, therefore, we choose depths 5 to build the classification tree model.

```{r , echo = T, fig.dim=c(6,4)}
set.seed(1)
Churnfit <- rpart(Churn ~ TotalCharges + MonthlyCharges + tenure + Contract +  OnlineSecurity + PaymentMethod, data=customerNum, method="class", control = list(maxdepth = 5) )

printcp(Churnfit) # display the results 
plotcp(Churnfit) # visualize cross-validation results 
summary(Churnfit) # detailed summary of splits

# plot tree 
plot(Churnfit, uniform=TRUE, main="Classification Tree for Churn")
text(Churnfit, use.n=TRUE, all=TRUE, cex=.8)

```

```{r  }
# create attractive postcript plot of tree 
post(Churnfit, file = "ChurnTree2.ps", title = "Classification Tree for Churn")
```



```{r , include=T}
loadPkg("caret") 
cm = confusionMatrix( predict(Churnfit, type = "class") , reference = customerNum[, "Churn"])
print('Overall: ')
cm$overall
print('Class: ')
cm$byClass
unloadPkg("caret")
```


The overall accuracy is `r round(cm$overall["Accuracy"]*100, digits=2)`%. These are the same metrics of sensitivity (also known as recall rate, TP / (TP+FN) ), specificity (TN / (TN+FP) ), F1 score, and others that we used in Logistic Regression and KNN analyses. Indeed, any "classifiers" can use the confustion matrix approach as one of the evaluation tools. 


```{r Classification Tree, results="asis"}
xkabledply(cm$table, "confusion matrix")
```

Next, we can try two other ways to plot the tree, with library `rpart.plot` and a "fancy" plot using the library `rattle`.

```{r Classification Tree fancyplot}
loadPkg("rpart.plot")
rpart.plot(Churnfit)
loadPkg("rattle") 
fancyRpartPlot(Churnfit)
```

Then we can prune the tree.

```{r Classification Tree prune}
#prune the tree 
Churnfit <- prune(Churnfit, cp = Churnfit$cptable[2,"CP"])

# plot the pruned tree 
fancyRpartPlot(Churnfit)
# For boring plot, use codes below instead
plot(Churnfit, uniform=TRUE, main="Pruned Classification Tree for Churn")
text(Churnfit, use.n=TRUE, all=TRUE, cex=.8)
```



```{R ROC curve of Classification Tree}
# library(rpart)
# rp <- rpart(Churn ~ ., data = customerNum)
library(ROCR)
tree.predict.prob = predict(Churnfit, type = "prob")
tree.pred <- prediction(tree.predict.prob[, 2], customerNum$Churn)
plot(performance(tree.pred, "tpr", "fpr"), main = "ROC of tree")
auc = performance(tree.pred, 'auc')
slot(auc, 'y.values')
abline(0, 1, lty = 2)
```

## SVM

Firstly, we need to load the package for SVM model training.

```{r loadpkg for SVM,results='markup'}
# install.packages(tidyverse)
# install.packages(kernlab)
# install.packages(e1071)
# install.packages(caTools)
library(tidyverse)#SVM
library(kernlab)#SVM
library(e1071)#SVM
library(caTools)#Split Data into Test and Train Set
library(ModelMetrics)#confusion matrix
library(ROCR)#ROC plot
```

Then, we set up 75% of total data as the training set, and the rest of them are test set.

```{r data splitting,results='markup'}
dat=subset(customer,select=-c(customerID))
set.seed(123)
split <- sample.split(dat, SplitRatio = 0.75)
# split
train_svm <- subset(dat, split == "TRUE")
test_svm <- subset(dat, split == "FALSE")
```

In this case, we decided to use `tune` function from `e1071` package to train SVM model. There are 4 types of kernel we can use: radial, linear, polynomial and sigmoid.
In fact, running these models do cost a lot of time, so we have to change the sample amount of our training set. To save the running time and quickly check the process, we tried to use the less data (200 sample here only) here for showing the template of our process.

### SVM with radial kernel

```{r train radial SVM,results='markup'}
# tune model to find optimal cost, gamma values
tune.out <- tune(svm, Churn~., data = train_svm[1:200,], kernel = "radial",
                 ranges = list(cost = c(0.1,1,10,100,1000),
                 gamma = c(0.5,1,2,3,4)))
# show best model
tune.out$best.model
```

```{r best radial SVM,results='markup'}
print('The parameter of best svm model with radial basis kernel is:')
tune.out$best.parameters
best_svmfit <- svm(Churn~., data = train_svm, kernel = "radial", gamma = 0.5, cost = 1,probability = TRUE)
```

### SVM with linear kernel

```{r train linear SVM,results='markup'}
# tune model to find optimal cost, gamma values
tune.out.linear <- tune(svm, Churn~., data = train_svm[1:200,], kernel = "linear",
                 ranges = list(cost = c(0.1,1,10,100,1000)))
# show best model
tune.out.linear$best.model
```

```{r best linear SVM,results='markup'}
print('The parameter of best svm model with linear kernel is:')
tune.out.linear$best.parameters
best_svm_linear_fit <- svm(Churn~., data = train_svm, kernel = "linear", cost = 10,probability = TRUE)
```

### SVM with polynomial kernel


```{r train polynomial SVM,results='markup'}
# tune model to find optimal cost, gamma values
tune.out.polynomial <- tune(svm, Churn~., data = train_svm[1:200,], kernel = "polynomial",
                 ranges = list(cost = c(0.1,1,10,100,1000),
                               gamma = c(0.5,1,2,3,4)))
# show best model
tune.out.polynomial$best.model
```

```{r best polunomial SVM,results='markup'}
print('The parameter of best svm model with polynomial kernel is:')
tune.out.polynomial$best.parameters
best_svm_polynomial_fit <- svm(Churn~., data = train_svm, kernel = "polynomial", gamma = 0.1,cost = 0.5,probability = TRUE)
```

### SVM with sigmoid kernel

```{r train sigmoid SVM,results='markup'}
# tune model to find optimal cost, gamma values
tune.out.sigmoid <- tune(svm, Churn~., data = train_svm[1:200,], kernel = "sigmoid",
                 ranges = list(cost = c(0.1,1,10,100,1000),
                               gamma = c(0.5,1,2,3,4)))
# show best model
tune.out.sigmoid$best.model
```

```{r best sigmoid SVM,results='markup'}
print('The parameter of best svm model with sigmoid kernel is:')
tune.out.sigmoid$best.parameters
best_svm_sigmoid_fit <- svm(Churn~., data = train_svm, kernel = "sigmoid", gamma = 0.5, cost = 0.1,probability = TRUE)
```

### Evaluation for SVM models

After training the best model, we try use the test set to caculate the confusion matrix and relative evaluation score like accuracy, recall rate, F1 socre and so on.

These are the confusion matrix of these SVM model. The results below confusion matrix showed the evaluation score of these models.

SVM with radial kernel:

```{r confusion matrix for SVM radial,results='markup'}
library(gmodels)
c.radial <- CrossTable(test_svm$Churn, predict(best_svmfit,test_svm), prop.chisq = FALSE)

# validate model performance
# valid <- table(true = test_svm$Churn, pred = predict(best_svmfit,test_svm))
# valid
#method 2(confusion matrix)
loadPkg("caret") 

cm_radial = confusionMatrix( predict(best_svmfit,test_svm), reference = test_svm$Churn )
print('Overall of SVM radial kernel: ')
cm_radial$overall
print('Class of SVM radial kernel: ')
cm_radial$byClass
```

SVM with linear kernel:

```{r confusion matrix for SVM linear,results='markup'}
c.linear <- CrossTable(test_svm$Churn, predict(best_svm_linear_fit,test_svm), prop.chisq = FALSE)

cm_linear = confusionMatrix( predict(best_svm_linear_fit,test_svm), reference = test_svm$Churn )
print('Overall of SVM linear kernel: ')
cm_linear$overall
print('Class of SVM linear kernel: ')
cm_linear$byClass
```

SVM with polynomial kernel:

```{r confusion matrix for SVM polynomial,results='markup'}
c.polynomial <- CrossTable(test_svm$Churn, predict(best_svm_polynomial_fit,test_svm), prop.chisq = FALSE)

cm_polynomial = confusionMatrix( predict(tune.out.polynomial$best.model,test_svm), reference = test_svm$Churn )
print('Overall of SVM polynomial kernel: ')
cm_polynomial$overall
print('Class of SVM polynomial kernel: ')
cm_polynomial$byClass
```

SVM with sigmoid kernel:

```{r confusion matrix for SVM sigmoid,results='markup'}
c.sigmoid <- CrossTable(test_svm$Churn, predict(best_svm_sigmoid_fit,test_svm), prop.chisq = FALSE)

cm_sigmoid = confusionMatrix( predict(tune.out.sigmoid$best.model,test_svm), reference = test_svm$Churn )
print('Overall of SVM sigmoid kernel: ')
cm_sigmoid$overall
print('Class of SVM sigmoid kernel: ')
cm_sigmoid$byClass

unloadPkg("caret")
```

Finally, we plot ROC plot for comparison among the models we built above.

```{r ROC plot for all models,results='markup'}
x.svm.linear.prob <- predict(best_svm_linear_fit, type="prob", newdata=test_svm, probability = TRUE)
x.svm.linear.prob.rocr <- prediction(attr(x.svm.linear.prob, "probabilities")[,2], test_svm$Churn)
x.svm.linear.perf <- performance(x.svm.linear.prob.rocr, "tpr","fpr")
plot(x.svm.linear.perf, col=4)

# x.svm.prob <- predict(best_svmfit, type="prob", newdata=test_svm, probability = TRUE)
# x.svm.prob.rocr <- prediction(attr(x.svm.prob, "probabilities")[,2], test_svm$Churn)
# x.svm.perf <- performance(x.svm.prob.rocr, "tpr","fpr")
# plot(x.svm.perf, col=5, add=TRUE)

# x.svm.polynomial.prob <- predict(best_svm_polynomial_fit, type="prob", newdata=test_svm, probability = TRUE)
# x.svm.polynomial.prob.rocr <- prediction(attr(x.svm.prob, "probabilities")[,2], test_svm$Churn)
# x.svm.polynomial.perf <- performance(x.svm.polynomial.prob.rocr, "tpr","fpr")
# plot(x.svm.perf, col=6, add=TRUE)

# x.svm.sigmoid.prob <- predict(best_svm_sigmoid_fit, type="prob", newdata=test_svm, probability = TRUE)
# x.svm.sigmoid.prob.rocr <- prediction(attr(x.svm.prob, "probabilities")[,2], test_svm$Churn)
# x.svm.sigmoid.perf <- performance(x.svm.sigmoid.prob.rocr, "tpr","fpr")
# plot(x.svm.perf, col=7, add=TRUE)

# Draw a legend.
# legend(0.7, 0.3, c( 'logistic','KNN','Classification Tree','svm linear'), 1:4) #with KNN
legend(0.7, 0.3, c( 'logistic','Classification Tree','svm linear'), c(1,3,4))#withou KNN

#logistic
x.glm.prob <- predict(logistic_7, type = "response" )
x.glm.prob.rocr <- prediction(x.glm.prob, customer$Churn)
x.glm.perf <- performance(x.glm.prob.rocr, "tpr","fpr")
plot(x.glm.perf, col=1, add=TRUE)

#tree
x.tree.prob <- prediction(tree.predict.prob[, 2], customerNum$Churn)
plot(performance(x.tree.prob, "tpr", "fpr"), , col=3, add=TRUE)

#knn
# x.knn.prob <- prediction(knn.roc.prob, cus_test_y)
# plot(performance(x.knn.prob, "tpr", "fpr"), , col=2, add=TRUE)


```

Even though SVM model won the evaluation according to the accuracy among these model, we still have to choose logistic regression model as our best classification model because of its performance on the ROC Plot and its interpretability.